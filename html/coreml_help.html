<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.2" />
<title>coreml_help API documentation</title>
<meta name="description" content="Python helper functions to facilitate working with CoreML and ONNX and converting from one to the other …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.3em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:0.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:20%}#content{width:80%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:0.8em}.item .name{font-size:1.2em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>coreml_help</code></h1>
</header>
<section id="section-intro">
<p>Python helper functions to facilitate working with CoreML and ONNX and converting from one to the other.</p>
<p>These functions depend on package <code>coremltools</code>. If you are converting between ONNX and CoreML,
you will need <code>onnx_coreml</code>, <code>onnx</code>, and <code>onnxruntime</code> as well.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want <em>real</em> help with CoreML, I highly recommend <strong>Matthijs Holleman's</strong>
<em>“Core ML Survival Guide.”</em>. Informative and well-written.
Easy to read, as much as books on this subject can be.</p>
</div>
<p>Also,</p>
<div class="admonition tip">
<p class="admonition-title">Tip:&ensp;Use <strong>Netron</strong></p>
</div>
<p>In <code>coreml_help.py</code> you will find:</p>
<p>The class "CoremlBrowser" inspection and "model surgery" methods</p>
<pre><code>      show_nn         Show a summary of neural network layers by index or name
      connect_layers  Connect the output of one layer to the input of another
      delete_layers   Delete CoreML NN layers by *name*.
      get_nn          Get the layers object for a CoreML neural network
</code></pre>
<p>Convenience Functions:</p>
<pre><code>      show_nn          Show a summary of nn (Function equivalent of `show_nn` method)
      show_head
      show_tail        Convenience functions  of  method `show_nn`
      get_rand_images  Return images (jpg and png) randomly sampled from child dirs.
</code></pre>
<p>Model Execution and Calculation Functions:</p>
<pre><code>     norm_for_imagenet  Normalize using ImageNet values for mean and standard dev.
     pred_for_coreml    Run and show Predictions for a native CoreML model
     pred_for_onnx      Run and show Predictions for a native ONNX model
     pred_for_o2c       Run and show Predictions for a CoreML model converted from ONNX
     softmax
</code></pre>
<h2 id="use">Use</h2>
<p>To use, initialize a browser instance using the '.mlmodel' file</p>
<pre><code>  from coreml_help import CoremlBrowser
  cmb = CoremlBrowser(" ... a '.mlmodel' file " )
</code></pre>
<p>Then the following are initialized:</p>
<pre><code>  cmb.spec        # The protobuf spec
  cmb.nn          # The neural network object
  cmb.layers      # The nn layers array
  cmb.layer_dict  # maps layer names to layer indexes
  cmb.layer_count # the count of nn layers
  cmb.shaper      # The shape inference object for this model
</code></pre>
<p>To show layers 10 - 15 (including shapes)</p>
<pre><code>  cmb.show_nn(10,5)
</code></pre>
<p>To delete the layers named "conv_10" and "relu_14"</p>
<pre><code>  cmb.delete_layers(['conv_10', 'relu_14'])
</code></pre>
<p>I wrote these as a learning exercise for my own use. Feedback welcome.
Most of this is based on the work of others,
but there can be no question that any
bugs, errors, misstatements,and, especially, inept code constructs, are entirely mine.</p>
<hr>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;
Python helper functions to facilitate working with CoreML and ONNX and converting from one to the other.

These functions depend on package `coremltools`. If you are converting between ONNX and CoreML,
you will need `onnx_coreml`, `onnx`, and `onnxruntime` as well.

.. tip::
  If you want *real* help with CoreML, I highly recommend **Matthijs Holleman&#39;s**
  *“Core ML Survival Guide.”*. Informative and well-written.
  Easy to read, as much as books on this subject can be.

Also,

.. tip::    Use **Netron**

In `coreml_help.py` you will find:

The class &#34;CoremlBrowser&#34; inspection and &#34;model surgery&#34; methods
```
      show_nn         Show a summary of neural network layers by index or name
      connect_layers  Connect the output of one layer to the input of another
      delete_layers   Delete CoreML NN layers by *name*.
      get_nn          Get the layers object for a CoreML neural network
```
Convenience Functions:
```
      show_nn          Show a summary of nn (Function equivalent of `show_nn` method)
      show_head
      show_tail        Convenience functions  of  method `show_nn`
      get_rand_images  Return images (jpg and png) randomly sampled from child dirs.
```
Model Execution and Calculation Functions:
```
     norm_for_imagenet  Normalize using ImageNet values for mean and standard dev.
     pred_for_coreml    Run and show Predictions for a native CoreML model
     pred_for_onnx      Run and show Predictions for a native ONNX model
     pred_for_o2c       Run and show Predictions for a CoreML model converted from ONNX
     softmax
```
Use:

  To use, initialize a browser instance using the &#39;.mlmodel&#39; file

        from coreml_help import CoremlBrowser
        cmb = CoremlBrowser(&#34; ... a &#39;.mlmodel&#39; file &#34; )

  Then the following are initialized:

        cmb.spec        # The protobuf spec
        cmb.nn          # The neural network object
        cmb.layers      # The nn layers array
        cmb.layer_dict  # maps layer names to layer indexes
        cmb.layer_count # the count of nn layers
        cmb.shaper      # The shape inference object for this model

  To show layers 10 - 15 (including shapes)

        cmb.show_nn(10,5)

  To delete the layers named &#34;conv_10&#34; and &#34;relu_14&#34;

        cmb.delete_layers([&#39;conv_10&#39;, &#39;relu_14&#39;])


I wrote these as a learning exercise for my own use. Feedback welcome.
Most of this is based on the work of others,  but there can be no question that any
bugs, errors, misstatements,and, especially, inept code constructs, are entirely mine.

---------------------
&#34;&#34;&#34;

# Configuration, common imports and functions

import numpy as np
from pathlib import Path
from collections import namedtuple
from coremltools.proto import Model_pb2
import coremltools.models.model as cm
import coremltools.models.utils as cu

### Convenience Types
# If a type starts with a &#39;u&#39;, it is almost certainly one of these, and defined here
#
if &#39;uarray&#39; not in globals():
  from typing import Union, List
  from PIL    import Image
  from numpy  import ndarray

  uarray = Union[ndarray, List]
  uimage = Union[ndarray, Image.Image]
  upath  = Union[Path,str]

### Data , data sources and functions #########################

ImageRepo = namedtuple(&#39;ImageRepo&#39; ,&#34;mean std labels_url&#34;)

imagenet = ImageRepo( mean   = [0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225],
                      labels_url =&#39;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&#39; )

cifar    = ImageRepo( mean = [0.491, 0.482, 0.447], std=[0.247, 0.243, 0.261], labels_url=None)

mnist    = ImageRepo( mean = [0.15]*3, std  = [0.15]*3, labels_url=None)


# CoreML Model inspection

class CoremlBrowser(object):
  &#34;&#34;&#34;
  Encapsulates routines to browse and edit CoreML Models
  &#34;&#34;&#34;
  def __init__(self, mlmodel_file:upath):
    self.mlmodel_path = Path(mlmodel_file)
    &#34;&#34;&#34; Path to the mlmodel file&#34;&#34;&#34;
    self.spec   = cu.load_spec(self.mlmodel_path)
    &#34;&#34;&#34; (Protobuf) spec for the model&#34;&#34;&#34;
    self.shaper = cm.NeuralNetworkShaper(self.spec)
    &#34;&#34;&#34; Shape inference object for this model&#34;&#34;&#34;
    self.nn     = self.get_nn()
    &#34;&#34;&#34; Neural network layers object&#34;&#34;&#34;
    self.layers = self.nn.layers
    &#34;&#34;&#34; Neural network layers&#34;&#34;&#34;
    self.layer_count = len(self.layers)
    self.layer_dict = {layer.name:i for i,layer in enumerate(self.layers)}
    &#34;&#34;&#34; Maps a layer name to its index&#34;&#34;&#34;
    self.name_len_centile = int(np.percentile(np.array([len(l.name) for l in self.layers]), 90))

  def _repr(self):
    &#34;&#34;&#34;
    Show something more useful than &#34;object&#34; when called
    &#34;&#34;&#34;
    all_text = &#39;&#39;
    for n in (&#39;mlmodel_path&#39;,&#39;layer_count&#39;,&#39;spec.description&#39;):
      v = eval(f&#34;self.{n}&#34;)
      nv_text = f&#34;{n:17} = {v}&#34;
      print(nv_text)
      all_text.join(nv_text)
    return all_text


  def __repr__(self): return self._repr()


  def get_nn(self) -&gt; Model_pb2.Model.neuralNetwork:
    &#34;&#34;&#34;
    Get the layers object for a CoreML neural network.

    Args:
      spec (Model): The `protobuf` spec. for this CoreML model.
                    Returned by `coremltools.util.load_spec(&#34;file.mlmodel&#34;)`

    Return:
      The neural network layers of the model or an Attribute Error.
      The precise return type is determined by the value of `spec.WhichOneof(&#34;Type&#34;)`,
      which should be one of:

        - Model.neuralNetwork
        - Model.neuralNetworkClassifier
        - Model.neuralNetworkRegressor

    Raises:
      AttributeError: if spec is not one of the 3 neuralNetwork sub-classes

    &#34;&#34;&#34;

    nn_dict = dict(
        neuralNetwork = self.spec.neuralNetwork,
        neuralNetworkRegressor = self.spec.neuralNetworkRegressor,
        neuralNetworkClassifier = self.spec.neuralNetworkClassifier
    )
    nn = nn_dict[self.spec.WhichOneof(&#34;Type&#34;)]
    if nn is None: raise AttributeError(&#34;MLModel is not a neural network sub-class&#34;)
    return nn

### ------------------------------------------------ ###

# Field formatting functions
 # Item and line formatting functions

  _ph = &#39;~&#39;  # Placeholder char(s) for strings below ...
  @staticmethod
  def _tbd(self,l): return &#34;              - &#34;
  def _repf(self, rf): return str.join(&#39;x&#39;, [str(f) for f in rf]) if len(rf) != 0 else self._ph
  @staticmethod
  def _fmt_add(self,l): return f&#34;add     &#34;
  def _fmt_act(self,l): return f&#34;{l.activation.WhichOneof(&#39;NonlinearityType&#39;):8}&#34;
  def _fmt_pool(self, l): return f&#34;pool   &#34; + f&#34;          sz:{self._repf(l.pooling.kernelSize)}  str:{self._repf(l.pooling.stride)}&#34;
  def _fmt_concat(self, l): return f&#34;concat  &#34;
  def _fmt_reshape(self, l): return f&#34;reshape          target:{l.reshape.targetShape}&#34;

  def _fmt_bn(self, l):
    bn  = l.batchnorm
    bc  = f&#34;{bn.channels}&#34;
    return f&#34;bnorm  &#34; + f&#34;{bc:9} ep:{bn.epsilon:.3e}  wc:{len(bn.beta.floatValue) + len(bn.gamma.floatValue)}&#34;

  def _fmt_innerp(self, l):
    c   = l.innerProduct
    ic  = f&#34;{c.outputChannels}x{c.inputChannels}&#34;
    return f&#34;innerp &#34; + f&#34;{ic:9} wc:{len(c.weights.floatValue)}&#34;

  def _fmt_conv(self, l):
    c     = l.convolution
    kc    = f&#34;{c.outputChannels}x{c.kernelChannels}&#34;
    conv1 = f&#34;conv   &#34; + f&#34;{kc:9} sz:{self._repf(c.kernelSize)}  str:{self._repf(c.stride)}&#34;
    conv2 = f&#34;  dil:{self._repf(c.dilationFactor)}  wc:{len(c.weights.floatValue)}&#34;
    return conv1 + conv2

  # Maps layer types to formatting functions

  _fmt_funcs = dict(innerProduct=_fmt_innerp, reshape=_fmt_reshape,
                    convolution=_fmt_conv, batchnorm=_fmt_bn,
                    pooling=_fmt_pool, activation=_fmt_act,
                    add=_fmt_add, concat=_fmt_concat)

  def _fmt_shape(self, name: str) -&gt; str:
    &#34;&#34;&#34;
    Format the shape line
    &#34;&#34;&#34;
    try:
      s = self.shaper.shape(name)
    except IndexError as e:
      line = f&#34;      - {e} - &#34;
    else:
      line = f&#34;CHW: {s[&#39;C&#39;]} {s[&#39;H&#39;]} {s[&#39;W&#39;]}   SB:{s[&#39;S&#39;]}{s[&#39;B&#39;]}&#34;
    return line

  def _fmt_for_one_line(self, layer, li: int) -&gt; str:
    &#34;&#34;&#34;
    Format one nn layer to print on one line.

    This routine attempts (poorly, so far) to adjust field positions based
    on the length of the layer name.  Layer name length seems to vary
    from 3 chars (Models converted from ONNX) to 24 chars (Apple-generated CoreML models)

    &#34;&#34;&#34;
    # Field widths for one layer/line
    # layer = 3
    # layer_name (ln) = calculated (max 8)
    # shapes (assume 3x3-digit fields, on avg) = 9+2+2

    # Calculate and construct the parts for each line

    layer_typ   = layer.WhichOneof(&#39;layer&#39;)
    name_len    = self.name_len_centile
    _fmt_type   = self._fmt_funcs.get(layer_typ, self._tbd)

    w_inputs    = int(name_len * 2) + 4
    w_outputs   = name_len + 3

    layer_name  = format(f&#34;{layer.name}&#34;, f&#34;&lt;{name_len}s&#34;)
    inputs      = format(f&#34;[{str.join(&#39;, &#39;, layer.input)}]&#34;, f&#34;&lt;{w_inputs}s&#34;)
    outputs     = format(f&#34;[{str.join(&#39;, &#39;, layer.output)}]&#34;, f&#34;&lt;{w_outputs}s&#34;)
    shout       = self._fmt_shape(layer.name)

    # Assemble the line to print

    return f&#34;{li:3} {layer_name:5}  {inputs} {outputs} {shout:&gt;13}  {_fmt_type(self,layer)}&#34;

  def _fmt_for_two_lines(self,layer, li: int) -&gt; str:
    &#34;&#34;&#34;
    Format one nn layer to print on two lines.

    This routine attempts (poorly, so far) to adjust field positions based
    on the length of the layer name.  Layer name length seems to vary
    from 3 chars (Models converted from ONNX) up to 24 chars (Apple-generated CoreML models)

    &#34;&#34;&#34;

    # Calculate and construct the parts for each line

    layer_typ = layer.WhichOneof(&#39;layer&#39;)
    name_len  = self.name_len_centile
    _fmt_type = self._fmt_funcs.get(layer_typ, self._tbd)

    w_inputs  = name_len + 2  # int(name_len * 2) + 4
    w_outputs = name_len + 2

    sp         = f&#34;   &#34;
    layer_name = format(f&#34;{layer.name}&#34;, f&#34;&lt;{name_len}s&#34;)
    inputs     = format(f&#34;[{str.join(&#39;, &#39;, layer.input)}]&#34;, f&#34;&lt;{w_inputs}s&#34;)
    outputs    = format(f&#34;[{str.join(&#39;, &#39;, layer.output)}]&#34;, f&#34;&lt;{w_outputs}s&#34;)
    shout      = self._fmt_shape(layer.name)

    # Assemble the line(s) to print

    line1     = f&#34;{li:3} {layer_name:32} {inputs :&lt;24}  {_fmt_type(self,layer)}&#34;
    line2     = f&#34;{sp:3} {sp        :32} {outputs:&lt;24}  {shout}&#34;

    return line1 + &#34;\n&#34; + line2 + &#34;\n&#34;


  def show_nn(self,  start:Union[int,str]=0, count=4,  break_len=8 ) -&gt; None:
    &#34;&#34;&#34;
    Beginning at `nn` layer `start`, print a summary of `count` network layers

    Args:

      start (Union[int,str]): The starting layer. Can be an `int` (=&gt;Layer index) or a `str` (=&gt;Layer Name).
        Negative values work backward from the end, similar to lists.

      count (int): How many layers to summarize and print

      break_len (int): Formatting criteria. If most ( ~ 90% ) of the layer names are
        less than or equal to   &#34;break_len&#34;, one line is used, otherwise, two lines.

      Inconsistent or invalid values for start and count are repaired by reseting to appropriate defaults

    &#34;&#34;&#34;
    nn_count = self.layer_count

    # If necessary convert layer name to layer index
    if type(start) is str: start = self.layer_dict[start]

    # Fix any contradictory start and count values
    # If start is negative, simulate list behavior and work backwards from the end
    if count is None or count &lt;= 0 : count = 4
    if start &lt; 0                   : count = 3; start = nn_count + start
    if start + count &gt; nn_count    : start = nn_count - count

    sp = &#34;   &#34; # formatting spacer
    one_line_heading = f&#34;Lay Name{ sp:4}In{sp:8}Out{sp:6}Shapes{sp:7}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;
    two_line_heading = f&#34;Lay Name{sp:32}In/Out{sp:24}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;

    # If &gt;= 90% layer names are &#34;short&#34;, print layer on one line, otherwise use two
    if self.name_len_centile &lt;= break_len:
      format_layer = self._fmt_for_one_line
      heading      = one_line_heading
    else:
      format_layer = self._fmt_for_two_lines
      heading      = two_line_heading

    print(heading)

    # Format and print each layer, include shape values if available

    li = start

    for ly in self.layers[start:start+count]:
      print(format_layer(ly, li))
      li += 1


  &#34;&#34;&#34; 
  CoreML Model Surgery - connect and delete layers 
  &#34;&#34;&#34;

  def connect_layers(self, from_:str, to_:str, replace=True)-&gt;namedtuple:
    &#34;&#34;&#34;
    Connect the output of one CoreML model layer to the input of another.

    Layers are identified by name. An invalid layer name aborts any connection attempt.
    Note that when two layers are *connected*, only one layer is modified:
    the only field that changes is the **to** layer&#39;s *input* field. Note also
    that the  keyword arguments `from_` and `to_` are suffixed by underscores.

    Args:
      from_ (str): The name of the layer supplying the outputs

      to_ (str): The name of the layer receiving the `from` outputs.
                   This layer&#39;s `input` field is modified.

      replace (bool): *True* (default) Replaces (overwrites)
                  the &#39;to&#39; layer&#39;s input with the &#39;from&#39; layer&#39;s output.
                  *False* appends the &#39;from&#39; layer&#39;s output to the the &#39;to&#39; layer&#39;s input.

    Return:
      A named tuple describing the change (see examples that follow)

    Examples:

          cmb = CoremlBrowser( ... path to &#39;mlmodel&#39; file ...)

          cmb.connect_layers(from_=&#39;conv336&#39;, to_=&#39;bnorm409&#39;)

      returns:

          ( changed_layer = &#39;bnorm409&#39;,
            input_before  = [&#39;concat408_output&#39;, &#39;add400_output&#39;],
            input_after   = [&#39;conv336_output&#39;] )


          connect_layers(nn, from_=&#39;conv100&#39;, to_=&#39;concat408&#39;)

      returns:

          (changed_layer =  &#39;None&#39;, error = &#34;Layer [&#39;conv100&#39;] not found&#34;)

    &#34;&#34;&#34;
    from copy import deepcopy

    ldict        = self.layer_dict
    layers       = self.layers
    layer_change = namedtuple(&#39;layer_audit&#39;,&#39;changed_layer input_before input_after error&#39;)
    layer_names  = ldict.keys()
    missing      = [ name for name  in [from_, to_] if name not in layer_names ]

    if len(missing) &gt; 0: return layer_change(changed_layer = &#34;NONE&#34;,
                                             error         = f&#34;Layer(s) {[missing]} not found&#34;,
                                             input_before  = None,
                                             input_after   = None )
    from_layer   = layers[ldict[from_]]
    to_layer     = layers[ldict[to_]]
    input_before = deepcopy(to_layer.input)

    if replace :  # remove the current inputs
      for i in range(len(to_layer.input)):
        to_layer.input.pop()

    for i in range(len(from_layer.output)):
      to_layer.input.append(from_layer.output[i])

    return layer_change(changed_layer = to_layer.name,
                        input_before  = input_before,
                        input_after   = deepcopy(to_layer.input),
                        error = None )


  def delete_layers(self, names_to_delete:[str])-&gt;[dict]:
    &#34;&#34;&#34;
    Delete NN layers by **name**.  Invalid layer names are silently ignored.

    Args:
      names_to_delete ([str]): list of layer names

    Return:
      An array of dicts, one for each deletion

    Example:

          delete_layers(nn,[&#39;conv335&#39;,&#39;bn400&#39;,&#39;avt500&#39;]) # ( assume &#39;avt500&#39; does not exist)

        returns:
          [
            {&#39;deleted_layer&#39;: &#39;conv335&#39;,  &#39;input&#39;: [&#39;bn334&#39;], &#39;output&#39;: [&#39;conv335&#39;]},
            {&#39;deleted_layer&#39;: &#39;bn400&#39;, &#39;input&#39;: [&#39;conv399&#39;], &#39;output&#39;: [&#39;bn400&#39;]},
          ]

    &#34;&#34;&#34;
    from copy import deepcopy
    deleted = []

    for target_name in names_to_delete:
      # to be safe, we have to re-enumerate after every deletion
      for i, layer in enumerate(self.layers):
        if layer.name == target_name :
          deleted.append(
            dict( deleted_layer=target_name, input=deepcopy(layer.input), output=deepcopy(layer.output))
          )
          del self.layers[i]
          break

    # Update the layer count and layer dict kept by the Coreml browser instance
    self.layer_count = len(self.layers)
    self.layer_dict  = {layer.name:i for i,layer in enumerate(self.layers)}

    return deleted

# Convenience Routines

def show_nn(cmb:CoremlBrowser, start:Union[int, str]=0, count=4, break_len=8):
  &#34;&#34;&#34; Convenience for `CoremlBrowser.show_nn()`&#34;&#34;&#34;
  cmb.show_nn(start, count=count, break_len=break_len)


def show_head(cmb:CoremlBrowser):
  &#34;&#34;&#34; Convenience for `show_nn(nn,0,3)`&#34;&#34;&#34;
  show_nn(cmb, 0, 3)

def show_tail(cmb:CoremlBrowser):
  &#34;&#34;&#34; Convenience for `show_nn(nn,-3)`&#34;&#34;&#34;
  show_nn( cmb, -3)


def get_shapes( mlmodelc: upath ) -&gt; dict:
  &#34;&#34;&#34;
  Get the shape of the network layers from the &#39;model.espresso.shape&#39; file generated by compiling *.mlmodel*
    (Not really used since incorporation of &#39;NeuralNetworkShaper&#39; object

  Args:
    mlmodelc(str): The *directory* containing the complied model. If the model name is *&#34;xyz.mlmodel&#34;*,
    this directory will be named *&#34;xyz.mlmodelc&#34;*, in the same directory as the *mlmodel* file (usually).

  Return:
    Dictionary of tuples keyed by layer name. Each tuple is a triplet (C,H,W)
    representing the output shape of that layer.

        `{ layer0_name:(C,H,W), layer1_name:(C,H,W), ... }`
  &#34;&#34;&#34;
  import json

  mlmodelc = Path(mlmodelc)
  if  mlmodelc is not None  \
      and mlmodelc.exists() \
      and mlmodelc.is_dir() :
    with open(mlmodelc/&#39;model.espresso.shape&#39;) as f: shape_dict = json.load(f)
    shapes = { k:(ls[&#39;k&#39;],ls[&#39;w&#39;],ls[&#39;h&#39;]) for k,ls in shape_dict[&#39;layer_shapes&#39;].items() }
  else:
    raise NotADirectoryError(f&#34;mlmodelc = &#39;{mlmodelc}&#39;&#34;)
  return shapes


&#34;&#34;&#34; 
Layer Calculations
&#34;&#34;&#34;

def softmax( x:uarray )-&gt;ndarray:
  &#34;&#34;&#34;
  Scale values to be between 0.0 - 1.0 so they can be used as probabilities.
  Formula is:
  
      exp(x)/sum(exp(x))

  Args:
    x (Union[List,ndarray]): Values on which to calculate the softmax.
                             Should be ndarray or convertible to an ndarray

  Returns:
    softmax as ndarray

  &#34;&#34;&#34;

  np_exp = np.exp(np.array(x))
  return np_exp / np.sum(np_exp, axis=0)


def norm_for_imagenet( img:uimage )-&gt;ndarray:
  &#34;&#34;&#34;
  Normalize an image using ImageNet values for mean and standard deviation.

  For each pixel in each channel, scale to the interval [0.0, 1.0] and then
  normalize using the mean and standard deviation from ImageNet.
  The input values are assumed to range from 0-255,
  input type is assumed to be an ndarray,
  or an image format that can be converted to an ndarray.
  Here is the formula:

      normalized_value = (value/255.0 - mean)/stddev
      
      mean = [0.485, 0.456, 0.406]
      std  = [0.229, 0.224, 0.225]

  Args:
    img (Union[ndarray, Image.Image]):
      Image data with values between 0-255. 
      If not an ndarray, must be convertible to one.
      Shape must be either (3,_,_) or (_,_,3)

  Return:
    Normalized image data as an ndarray[float32]

  Raises:
    ValueError: If image shape is not (3,_,_) or (_,_,3), or number of dimensions is not 3

  &#34;&#34;&#34;
  img = np.array(img)
  if img.ndim != 3 : raise ValueError(f&#34;Image has {img.ndim} dimensions, expected 3&#34;)

  # Mean and Stddev for image net
  mean  = imagenet.mean
  std   = imagenet.std

  shape = img.shape
  nimg  = np.zeros(shape).astype(&#39;float32&#39;)

  # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize
  if shape[0] == 3:
    for i in range(3): nimg[i, :, :] = (img[i, :, :] / 255.0 - mean[i]) / std[i]
  elif shape[2] == 3:
    for i in range(3): nimg[:, :, i] = (img[:, :, i] / 255.0 - mean[i]) / std[i]
  else:
    raise ValueError(f&#34;Image shape is {shape}, expected (3,_,_) or (_,_,3)&#34;)

  return nimg


&#34;&#34;&#34; 
Model Execution and Prediction
&#34;&#34;&#34;

def pred_for_o2c(model, img, n_top=3, in_name=&#39;data&#39;, out_name=&#39;resnetv24_dense0_fwd&#39;, labels=None):
  &#34;&#34;&#34;
  Run the CoreML Classifier model that was converted from ONNX and return the top results.

  This function converts the output from the final layer to a list of probabilities,
  then extracts the top items and associated labels.

  This step is needed because the ONNX Resnet50 model does not contain a final softmax layer, and the
  conversion to CoreML does not add one. (The native CoreML Resnet50 does have a softmax layer)

  Args:
    model (object): The CoreML model to use for inference
    img (Image.Image): The image to process. Expected to be an image with values 0-255
    in_name (str): Starting Layer Input name
    out_name (str): Final Layer Output name
    n_top (int): Number of top values to return (default 3)
    labels ([str]): Class Labels for output

  Return:
    dict with four items:

      - topI [ Indexes to top probabilities ], from np.argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ]
      - topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None
  &#34;&#34;&#34;

  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]
  try:
    y = model.predict({in_name:img}, usesCPUOnly=True)

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:
    r    = y[out_name]
    res  = np.squeeze(np.array(r))
    prob = softmax(res)
    topI = np.argsort(prob)[:-(n_top+1):-1]
    topP = [ prob[i]*100 for i in topI ],
    topL = [ labels[i]   for i in topI ],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]
    #
  return dict(topI=topI , topP=topP, topL=topL, topRes=topRes)


def pred_for_onnx(sess, img:uimage, n_top=3, labels=None):
  &#34;&#34;&#34;
  Run the ONNX Classifier model and return the top results.

  This function

    - normalizes the image data,
    - if needed, massages the data to a shape of (3,_,_)
    - runs the model using `onnxruntime`
    - converts the output from the final layer to a list of probabilities,
    - extracts the top items and associated labels.

  Args:
    sess (object) : the ONNX run-time session(model) to use for prediction
    img (Union[ndarray,Image.Image]):  image or image data to use for test
    n_top (int): Number of top values to return (default 4)
    labels ([str]): Class labels for output

  Return:
    Dict with four items:
    
      - topI [ Indexes to top probabilities ], from argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ]
      - topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None
  &#34;&#34;&#34;
  # Use the image to generate acceptable input for the model
  # - move axes if needed, normalize, add a dimension to make it (1,3,224,224)
  nimg  = np.array(img)
  nimg2 = np.moveaxis(nimg,[0,1,2],[1,2,0]) if nimg.shape[2] == 3 else nimg
  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]

  try: pimg  = norm_for_imagenet(nimg2)
  except Exception as e :
    print(&#39;Exception:&#39;,e)
    return dict(topI=topI, topP=topP, topL=topL, topRes=topRes)

  x     = np.array([pimg])
  # Get input and output names for the model
  input0 = sess.get_inputs()[0]
  output = sess.get_outputs()[0]
  input0_name = input0.name
  output_name = output.name

  # Run the model
  try:
    r = sess.run([output_name], {input0_name: x})

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:  # Get predictions from the results
    res  = np.squeeze(np.array(r))  # eliminate dimensions w/ len=1 , e.g. from (1,1,1000) --&gt; (1000,)
    prob = softmax(res)
    topI = np.argsort(prob)[:-(n_top+1):-1]
    topP = [ prob[i]*100 for i in topI ],
    topL = [ labels[i]   for i in topI ],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]

  return dict(topI=topI, topP=topP, topL=topL, topRes=topRes)


def pred_for_coreml(model, img, n_top=3, in_name=&#39;image&#39;, out_name=&#39;classLabelProbs&#39;):
  &#34;&#34;&#34;
  Run a native CoreML Classifier and return the top results.

  Args:
    model (object) : the coreml model to use for the prediction
    in_name (str): Starting Input Layer name
    out_name (str): Final Output Layer name
    img (Image.Image): fitted image to use for test
    n_top (int): Number of top values to return (default 3)

  Return:
    dict with four items:

      - topI [ Indexes to top probabilities ], from argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ] or [] if labels=None
      - topRes [ Top Labels and probabilities as formatted strings ] or [] if labels=None

  &#34;&#34;&#34;
  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]

  try:
    y = model.predict({in_name:img}, usesCPUOnly=True)

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:
    pdict  = y[out_name]
    prob   = np.array([v for v in pdict.values()])
    labels = np.array([k for k in pdict.keys()])
    topI   = np.argsort(prob)[:-(n_top+1):-1]
    topP   = [prob[i] * 100 for i in topI],
    topL   = [labels[i] for i in topI],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]

  return dict( topI=topI, topP=topP, topL=topL, topRes=topRes)


def _is_imgfile(f:upath)-&gt;bool:
  &#34;&#34;&#34;True if the file ends in &#39;jpg&#39; or &#39;png&#39; &#34;&#34;&#34;
  f = Path(f)
  return f.is_file() and (f.suffix == &#39;.jpg&#39; or f.suffix == &#39;.png&#39;)


def _rand_imgs_fm_dir(dir_path: upath, n_images=40, limit=400) -&gt; list:
  &#34;&#34;&#34;
  Return a list of image file names chosen randomly from `dir_path`.

  Args:
    dir_path(upath): Path or str for the directory
    n_images (int):  Requested number of image file names
    limit (int):     Limit the number of files used for the random sample.
                     Avoids un-intentional sampling of very large directorys.

  Returns:
    A list of randomly chosen &#39;.jpg&#39; or &#39;.png&#39; file names.
    Number of files returned could be less than the requested amount

  Note:
    Only known to work on Unixen systems.

  &#34;&#34;&#34;
  import random

  dir_path = Path(dir_path)
  nlink_count = dir_path.stat().st_nlink  # The file count in directory (so far)
  max_files = min(limit, nlink_count)  # max num files to search in any direct

  # Collect  image files from directory and return a random sample

  imgs_in_dir = [f for i, f in zip(range(max_files), dir_path.iterdir()) if _is_imgfile(f)]
  return random.sample(imgs_in_dir, min(len(imgs_in_dir), n_images))


def get_rand_images(dir_path: upath, n_images=100, search_limit=400) -&gt; list:
  &#34;&#34;&#34;
  Return images (jpg and png) randomly sampled from child directories.

  Args:
    dir_path (upath): The parent directory of the children to search
    n_images (int)  : Total number of images to return (actual number may be less)
    search_limit (int) : Limit on the number of files to sample.
                         (To avoid performance issues with very large file counts)

  Returns:
    List of image files. Count may be less than requested.

  &#34;&#34;&#34;
  dir_path = Path(dir_path)

  # Generate list of directories to search for images
  dirs = [d for d in dir_path.iterdir() if d.is_dir()]
  imgs_per_dir = max(1, int(n_images / len(dirs)))
  img_files = []

  for d in dirs:  # Accumulate random images from each child directory in turn
    r = _rand_imgs_fm_dir(d, n_images=imgs_per_dir, limit=search_limit)
    img_files.extend(r)

  return img_files


def _get_labels(repo: Union[ImageRepo, str]) -&gt; list:
  &#34;&#34;&#34;
   Get the labels for the specified data source - still a work in progress

   If the data is available locally, use that, otherwise download and save locally

   Args:
     repo (ImageRepo,str): namedTuple for the data source (See example) or a file path as str

   Return:
     List containing the labels

   Example:
     The &#39;imagenet&#39; ImageRepo looks like this:

          imagenet =
              ImageRepo(mean   = [0.485, 0.456, 0.406],
                        std    = [0.229, 0.224, 0.225],
                        url    = None,
                        labels_url =&#39;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&#39;,
                        local  = data_root/&#39;imagenet&#39;,
                        images = None,
                        labels = data_root/&#39;imagenet/imagenet_labels.txt&#39;,
                       )

   &#34;&#34;&#34;
  labels_file = repo if type(repo) is str else repo.labels
  if labels_file is not None:
    with open(labels_file, &#39;r&#39;) as list_:
      labels = [line.rstrip() for line in list_]
  else:
    raise NotImplementedError(&#39;Labels file not found locally.  Please download and try again&#39;)
  return labels


def main():
  print(&#34;\ncoreml help functions loaded&#34;)


if __name__ == &#39;__main__&#39;: main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="coreml_help.get_rand_images"><code class="name flex">
<span>def <span class="ident">get_rand_images</span></span>(<span>dir_path, n_images=100, search_limit=400)</span>
</code></dt>
<dd>
<section class="desc"><p>Return images (jpg and png) randomly sampled from child directories.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dir_path</code></strong> :&ensp;<code>upath</code></dt>
<dd>The parent directory of the children to search</dd>
</dl>
<p>n_images (int)
: Total number of images to return (actual number may be less)
search_limit (int) : Limit on the number of files to sample.
(To avoid performance issues with very large file counts)</p>
<h2 id="returns">Returns</h2>
<p>List of image files. Count may be less than requested.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_rand_images(dir_path: upath, n_images=100, search_limit=400) -&gt; list:
  &#34;&#34;&#34;
  Return images (jpg and png) randomly sampled from child directories.

  Args:
    dir_path (upath): The parent directory of the children to search
    n_images (int)  : Total number of images to return (actual number may be less)
    search_limit (int) : Limit on the number of files to sample.
                         (To avoid performance issues with very large file counts)

  Returns:
    List of image files. Count may be less than requested.

  &#34;&#34;&#34;
  dir_path = Path(dir_path)

  # Generate list of directories to search for images
  dirs = [d for d in dir_path.iterdir() if d.is_dir()]
  imgs_per_dir = max(1, int(n_images / len(dirs)))
  img_files = []

  for d in dirs:  # Accumulate random images from each child directory in turn
    r = _rand_imgs_fm_dir(d, n_images=imgs_per_dir, limit=search_limit)
    img_files.extend(r)

  return img_files</code></pre>
</details>
</dd>
<dt id="coreml_help.get_shapes"><code class="name flex">
<span>def <span class="ident">get_shapes</span></span>(<span>mlmodelc)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the shape of the network layers from the 'model.espresso.shape' file generated by compiling <em>.mlmodel</em>
(Not really used since incorporation of 'NeuralNetworkShaper' object</p>
<h2 id="args">Args</h2>
<p>mlmodelc(str): The <em>directory</em> containing the complied model. If the model name is <em>"xyz.mlmodel"</em>,
this directory will be named <em>"xyz.mlmodelc"</em>, in the same directory as the <em>mlmodel</em> file (usually).</p>
<h2 id="return">Return</h2>
<p>Dictionary of tuples keyed by layer name. Each tuple is a triplet (C,H,W)
representing the output shape of that layer.</p>
<pre><code>`{ layer0_name:(C,H,W), layer1_name:(C,H,W), ... }`
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_shapes( mlmodelc: upath ) -&gt; dict:
  &#34;&#34;&#34;
  Get the shape of the network layers from the &#39;model.espresso.shape&#39; file generated by compiling *.mlmodel*
    (Not really used since incorporation of &#39;NeuralNetworkShaper&#39; object

  Args:
    mlmodelc(str): The *directory* containing the complied model. If the model name is *&#34;xyz.mlmodel&#34;*,
    this directory will be named *&#34;xyz.mlmodelc&#34;*, in the same directory as the *mlmodel* file (usually).

  Return:
    Dictionary of tuples keyed by layer name. Each tuple is a triplet (C,H,W)
    representing the output shape of that layer.

        `{ layer0_name:(C,H,W), layer1_name:(C,H,W), ... }`
  &#34;&#34;&#34;
  import json

  mlmodelc = Path(mlmodelc)
  if  mlmodelc is not None  \
      and mlmodelc.exists() \
      and mlmodelc.is_dir() :
    with open(mlmodelc/&#39;model.espresso.shape&#39;) as f: shape_dict = json.load(f)
    shapes = { k:(ls[&#39;k&#39;],ls[&#39;w&#39;],ls[&#39;h&#39;]) for k,ls in shape_dict[&#39;layer_shapes&#39;].items() }
  else:
    raise NotADirectoryError(f&#34;mlmodelc = &#39;{mlmodelc}&#39;&#34;)
  return shapes</code></pre>
</details>
</dd>
<dt id="coreml_help.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def main():
  print(&#34;\ncoreml help functions loaded&#34;)</code></pre>
</details>
</dd>
<dt id="coreml_help.norm_for_imagenet"><code class="name flex">
<span>def <span class="ident">norm_for_imagenet</span></span>(<span>img)</span>
</code></dt>
<dd>
<section class="desc"><p>Normalize an image using ImageNet values for mean and standard deviation.</p>
<p>For each pixel in each channel, scale to the interval [0.0, 1.0] and then
normalize using the mean and standard deviation from ImageNet.
The input values are assumed to range from 0-255,
input type is assumed to be an ndarray,
or an image format that can be converted to an ndarray.
Here is the formula:</p>
<pre><code>normalized_value = (value/255.0 - mean)/stddev

mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]
</code></pre>
<h2 id="args">Args</h2>
<p>img (Union[ndarray, Image.Image]):
Image data with values between 0-255.
If not an ndarray, must be convertible to one.
Shape must be either (3,<em>,</em>) or (<em>,</em>,3)</p>
<h2 id="return">Return</h2>
<p>Normalized image data as an ndarray[float32]</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong></dt>
<dd>If image shape is not (3,<em>,</em>) or (<em>,</em>,3), or number of dimensions is not 3</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def norm_for_imagenet( img:uimage )-&gt;ndarray:
  &#34;&#34;&#34;
  Normalize an image using ImageNet values for mean and standard deviation.

  For each pixel in each channel, scale to the interval [0.0, 1.0] and then
  normalize using the mean and standard deviation from ImageNet.
  The input values are assumed to range from 0-255,
  input type is assumed to be an ndarray,
  or an image format that can be converted to an ndarray.
  Here is the formula:

      normalized_value = (value/255.0 - mean)/stddev
      
      mean = [0.485, 0.456, 0.406]
      std  = [0.229, 0.224, 0.225]

  Args:
    img (Union[ndarray, Image.Image]):
      Image data with values between 0-255. 
      If not an ndarray, must be convertible to one.
      Shape must be either (3,_,_) or (_,_,3)

  Return:
    Normalized image data as an ndarray[float32]

  Raises:
    ValueError: If image shape is not (3,_,_) or (_,_,3), or number of dimensions is not 3

  &#34;&#34;&#34;
  img = np.array(img)
  if img.ndim != 3 : raise ValueError(f&#34;Image has {img.ndim} dimensions, expected 3&#34;)

  # Mean and Stddev for image net
  mean  = imagenet.mean
  std   = imagenet.std

  shape = img.shape
  nimg  = np.zeros(shape).astype(&#39;float32&#39;)

  # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize
  if shape[0] == 3:
    for i in range(3): nimg[i, :, :] = (img[i, :, :] / 255.0 - mean[i]) / std[i]
  elif shape[2] == 3:
    for i in range(3): nimg[:, :, i] = (img[:, :, i] / 255.0 - mean[i]) / std[i]
  else:
    raise ValueError(f&#34;Image shape is {shape}, expected (3,_,_) or (_,_,3)&#34;)

  return nimg</code></pre>
</details>
</dd>
<dt id="coreml_help.pred_for_coreml"><code class="name flex">
<span>def <span class="ident">pred_for_coreml</span></span>(<span>model, img, n_top=3, in_name='image', out_name='classLabelProbs')</span>
</code></dt>
<dd>
<section class="desc"><p>Run a native CoreML Classifier and return the top results.</p>
<h2 id="args">Args</h2>
<dl>
<dt>model (object) : the coreml model to use for the prediction</dt>
<dt><strong><code>in_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Starting Input Layer name</dd>
<dt><strong><code>out_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Final Output Layer name</dd>
<dt><strong><code>img</code></strong> :&ensp;<code>Image.Image</code></dt>
<dd>fitted image to use for test</dd>
<dt><strong><code>n_top</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of top values to return (default 3)</dd>
</dl>
<h2 id="return">Return</h2>
<p>dict with four items:</p>
<ul>
<li>topI [ Indexes to top probabilities ], from argsort</li>
<li>topP [ Top probabilities ]</li>
<li>topL [ Top Labels ] or [] if labels=None</li>
<li>topRes [ Top Labels and probabilities as formatted strings ] or [] if labels=None</li>
</ul></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def pred_for_coreml(model, img, n_top=3, in_name=&#39;image&#39;, out_name=&#39;classLabelProbs&#39;):
  &#34;&#34;&#34;
  Run a native CoreML Classifier and return the top results.

  Args:
    model (object) : the coreml model to use for the prediction
    in_name (str): Starting Input Layer name
    out_name (str): Final Output Layer name
    img (Image.Image): fitted image to use for test
    n_top (int): Number of top values to return (default 3)

  Return:
    dict with four items:

      - topI [ Indexes to top probabilities ], from argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ] or [] if labels=None
      - topRes [ Top Labels and probabilities as formatted strings ] or [] if labels=None

  &#34;&#34;&#34;
  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]

  try:
    y = model.predict({in_name:img}, usesCPUOnly=True)

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:
    pdict  = y[out_name]
    prob   = np.array([v for v in pdict.values()])
    labels = np.array([k for k in pdict.keys()])
    topI   = np.argsort(prob)[:-(n_top+1):-1]
    topP   = [prob[i] * 100 for i in topI],
    topL   = [labels[i] for i in topI],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]

  return dict( topI=topI, topP=topP, topL=topL, topRes=topRes)</code></pre>
</details>
</dd>
<dt id="coreml_help.pred_for_o2c"><code class="name flex">
<span>def <span class="ident">pred_for_o2c</span></span>(<span>model, img, n_top=3, in_name='data', out_name='resnetv24_dense0_fwd', labels=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Run the CoreML Classifier model that was converted from ONNX and return the top results.</p>
<p>This function converts the output from the final layer to a list of probabilities,
then extracts the top items and associated labels.</p>
<p>This step is needed because the ONNX Resnet50 model does not contain a final softmax layer, and the
conversion to CoreML does not add one. (The native CoreML Resnet50 does have a softmax layer)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>object</code></dt>
<dd>The CoreML model to use for inference</dd>
<dt><strong><code>img</code></strong> :&ensp;<code>Image.Image</code></dt>
<dd>The image to process. Expected to be an image with values 0-255</dd>
<dt><strong><code>in_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Starting Layer Input name</dd>
<dt><strong><code>out_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Final Layer Output name</dd>
<dt><strong><code>n_top</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of top values to return (default 3)</dd>
<dt><strong><code>labels</code></strong> :&ensp;[<code>str</code>]</dt>
<dd>Class Labels for output</dd>
</dl>
<h2 id="return">Return</h2>
<p>dict with four items:</p>
<ul>
<li>topI [ Indexes to top probabilities ], from np.argsort</li>
<li>topP [ Top probabilities ]</li>
<li>topL [ Top Labels ]</li>
<li>topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None</li>
</ul></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def pred_for_o2c(model, img, n_top=3, in_name=&#39;data&#39;, out_name=&#39;resnetv24_dense0_fwd&#39;, labels=None):
  &#34;&#34;&#34;
  Run the CoreML Classifier model that was converted from ONNX and return the top results.

  This function converts the output from the final layer to a list of probabilities,
  then extracts the top items and associated labels.

  This step is needed because the ONNX Resnet50 model does not contain a final softmax layer, and the
  conversion to CoreML does not add one. (The native CoreML Resnet50 does have a softmax layer)

  Args:
    model (object): The CoreML model to use for inference
    img (Image.Image): The image to process. Expected to be an image with values 0-255
    in_name (str): Starting Layer Input name
    out_name (str): Final Layer Output name
    n_top (int): Number of top values to return (default 3)
    labels ([str]): Class Labels for output

  Return:
    dict with four items:

      - topI [ Indexes to top probabilities ], from np.argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ]
      - topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None
  &#34;&#34;&#34;

  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]
  try:
    y = model.predict({in_name:img}, usesCPUOnly=True)

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:
    r    = y[out_name]
    res  = np.squeeze(np.array(r))
    prob = softmax(res)
    topI = np.argsort(prob)[:-(n_top+1):-1]
    topP = [ prob[i]*100 for i in topI ],
    topL = [ labels[i]   for i in topI ],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]
    #
  return dict(topI=topI , topP=topP, topL=topL, topRes=topRes)</code></pre>
</details>
</dd>
<dt id="coreml_help.pred_for_onnx"><code class="name flex">
<span>def <span class="ident">pred_for_onnx</span></span>(<span>sess, img, n_top=3, labels=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Run the ONNX Classifier model and return the top results.</p>
<p>This function</p>
<ul>
<li>normalizes the image data,</li>
<li>if needed, massages the data to a shape of (3,<em>,</em>)</li>
<li>runs the model using <code>onnxruntime</code></li>
<li>converts the output from the final layer to a list of probabilities,</li>
<li>extracts the top items and associated labels.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt>sess (object) : the ONNX run-time session(model) to use for prediction</dt>
<dt><strong><code>img</code></strong> :&ensp;<code>Union</code>[<code>ndarray</code>,<code>Image.Image</code>]</dt>
<dd>image or image data to use for test</dd>
<dt><strong><code>n_top</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of top values to return (default 4)</dd>
<dt><strong><code>labels</code></strong> :&ensp;[<code>str</code>]</dt>
<dd>Class labels for output</dd>
</dl>
<h2 id="return">Return</h2>
<p>Dict with four items:</p>
<ul>
<li>topI [ Indexes to top probabilities ], from argsort</li>
<li>topP [ Top probabilities ]</li>
<li>topL [ Top Labels ]</li>
<li>topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None</li>
</ul></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def pred_for_onnx(sess, img:uimage, n_top=3, labels=None):
  &#34;&#34;&#34;
  Run the ONNX Classifier model and return the top results.

  This function

    - normalizes the image data,
    - if needed, massages the data to a shape of (3,_,_)
    - runs the model using `onnxruntime`
    - converts the output from the final layer to a list of probabilities,
    - extracts the top items and associated labels.

  Args:
    sess (object) : the ONNX run-time session(model) to use for prediction
    img (Union[ndarray,Image.Image]):  image or image data to use for test
    n_top (int): Number of top values to return (default 4)
    labels ([str]): Class labels for output

  Return:
    Dict with four items:
    
      - topI [ Indexes to top probabilities ], from argsort
      - topP [ Top probabilities ]
      - topL [ Top Labels ]
      - topRes [ Top Labels and probabilities as formatted strings ], or [] if labels=None
  &#34;&#34;&#34;
  # Use the image to generate acceptable input for the model
  # - move axes if needed, normalize, add a dimension to make it (1,3,224,224)
  nimg  = np.array(img)
  nimg2 = np.moveaxis(nimg,[0,1,2],[1,2,0]) if nimg.shape[2] == 3 else nimg
  topI, topP, topL, topRes = [0], [0.00], [&#34;No Results&#34;], [&#34;No Results&#34;]

  try: pimg  = norm_for_imagenet(nimg2)
  except Exception as e :
    print(&#39;Exception:&#39;,e)
    return dict(topI=topI, topP=topP, topL=topL, topRes=topRes)

  x     = np.array([pimg])
  # Get input and output names for the model
  input0 = sess.get_inputs()[0]
  output = sess.get_outputs()[0]
  input0_name = input0.name
  output_name = output.name

  # Run the model
  try:
    r = sess.run([output_name], {input0_name: x})

  except Exception as e :
    topRes[0] = f&#34;No Results; Exception: {e}&#34;
    print(&#39;Exception:&#39;,e)

  else:  # Get predictions from the results
    res  = np.squeeze(np.array(r))  # eliminate dimensions w/ len=1 , e.g. from (1,1,1000) --&gt; (1000,)
    prob = softmax(res)
    topI = np.argsort(prob)[:-(n_top+1):-1]
    topP = [ prob[i]*100 for i in topI ],
    topL = [ labels[i]   for i in topI ],
    topRes = [f&#34;{labels[i][:30]:32} {100 * prob[i]:.4g}&#34; for i in topI]

  return dict(topI=topI, topP=topP, topL=topL, topRes=topRes)</code></pre>
</details>
</dd>
<dt id="coreml_help.show_head"><code class="name flex">
<span>def <span class="ident">show_head</span></span>(<span>cmb)</span>
</code></dt>
<dd>
<section class="desc"><p>Convenience for <code>show_nn(nn,0,3)</code></p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def show_head(cmb:CoremlBrowser):
  &#34;&#34;&#34; Convenience for `show_nn(nn,0,3)`&#34;&#34;&#34;
  show_nn(cmb, 0, 3)</code></pre>
</details>
</dd>
<dt id="coreml_help.show_nn"><code class="name flex">
<span>def <span class="ident">show_nn</span></span>(<span>cmb, start=0, count=4, break_len=8)</span>
</code></dt>
<dd>
<section class="desc"><p>Convenience for <a title="coreml_help.CoremlBrowser.show_nn" href="#coreml_help.CoremlBrowser.show_nn"><code>CoremlBrowser.show_nn()</code></a></p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def show_nn(cmb:CoremlBrowser, start:Union[int, str]=0, count=4, break_len=8):
  &#34;&#34;&#34; Convenience for `CoremlBrowser.show_nn()`&#34;&#34;&#34;
  cmb.show_nn(start, count=count, break_len=break_len)</code></pre>
</details>
</dd>
<dt id="coreml_help.show_tail"><code class="name flex">
<span>def <span class="ident">show_tail</span></span>(<span>cmb)</span>
</code></dt>
<dd>
<section class="desc"><p>Convenience for <code>show_nn(nn,-3)</code></p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def show_tail(cmb:CoremlBrowser):
  &#34;&#34;&#34; Convenience for `show_nn(nn,-3)`&#34;&#34;&#34;
  show_nn( cmb, -3)</code></pre>
</details>
</dd>
<dt id="coreml_help.softmax"><code class="name flex">
<span>def <span class="ident">softmax</span></span>(<span>x)</span>
</code></dt>
<dd>
<section class="desc"><p>Scale values to be between 0.0 - 1.0 so they can be used as probabilities.
Formula is:</p>
<pre><code>exp(x)/sum(exp(x))
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>Union</code>[<code>List</code>,<code>ndarray</code>]</dt>
<dd>Values on which to calculate the softmax.
Should be ndarray or convertible to an ndarray</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><a title="coreml_help.softmax" href="#coreml_help.softmax"><code>softmax()</code></a> <code>as</code> <code>ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def softmax( x:uarray )-&gt;ndarray:
  &#34;&#34;&#34;
  Scale values to be between 0.0 - 1.0 so they can be used as probabilities.
  Formula is:
  
      exp(x)/sum(exp(x))

  Args:
    x (Union[List,ndarray]): Values on which to calculate the softmax.
                             Should be ndarray or convertible to an ndarray

  Returns:
    softmax as ndarray

  &#34;&#34;&#34;

  np_exp = np.exp(np.array(x))
  return np_exp / np.sum(np_exp, axis=0)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="coreml_help.CoremlBrowser"><code class="flex name class">
<span>class <span class="ident">CoremlBrowser</span></span>
<span>(</span><span>mlmodel_file)</span>
</code></dt>
<dd>
<section class="desc"><p>Encapsulates routines to browse and edit CoreML Models</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class CoremlBrowser(object):
  &#34;&#34;&#34;
  Encapsulates routines to browse and edit CoreML Models
  &#34;&#34;&#34;
  def __init__(self, mlmodel_file:upath):
    self.mlmodel_path = Path(mlmodel_file)
    &#34;&#34;&#34; Path to the mlmodel file&#34;&#34;&#34;
    self.spec   = cu.load_spec(self.mlmodel_path)
    &#34;&#34;&#34; (Protobuf) spec for the model&#34;&#34;&#34;
    self.shaper = cm.NeuralNetworkShaper(self.spec)
    &#34;&#34;&#34; Shape inference object for this model&#34;&#34;&#34;
    self.nn     = self.get_nn()
    &#34;&#34;&#34; Neural network layers object&#34;&#34;&#34;
    self.layers = self.nn.layers
    &#34;&#34;&#34; Neural network layers&#34;&#34;&#34;
    self.layer_count = len(self.layers)
    self.layer_dict = {layer.name:i for i,layer in enumerate(self.layers)}
    &#34;&#34;&#34; Maps a layer name to its index&#34;&#34;&#34;
    self.name_len_centile = int(np.percentile(np.array([len(l.name) for l in self.layers]), 90))

  def _repr(self):
    &#34;&#34;&#34;
    Show something more useful than &#34;object&#34; when called
    &#34;&#34;&#34;
    all_text = &#39;&#39;
    for n in (&#39;mlmodel_path&#39;,&#39;layer_count&#39;,&#39;spec.description&#39;):
      v = eval(f&#34;self.{n}&#34;)
      nv_text = f&#34;{n:17} = {v}&#34;
      print(nv_text)
      all_text.join(nv_text)
    return all_text


  def __repr__(self): return self._repr()


  def get_nn(self) -&gt; Model_pb2.Model.neuralNetwork:
    &#34;&#34;&#34;
    Get the layers object for a CoreML neural network.

    Args:
      spec (Model): The `protobuf` spec. for this CoreML model.
                    Returned by `coremltools.util.load_spec(&#34;file.mlmodel&#34;)`

    Return:
      The neural network layers of the model or an Attribute Error.
      The precise return type is determined by the value of `spec.WhichOneof(&#34;Type&#34;)`,
      which should be one of:

        - Model.neuralNetwork
        - Model.neuralNetworkClassifier
        - Model.neuralNetworkRegressor

    Raises:
      AttributeError: if spec is not one of the 3 neuralNetwork sub-classes

    &#34;&#34;&#34;

    nn_dict = dict(
        neuralNetwork = self.spec.neuralNetwork,
        neuralNetworkRegressor = self.spec.neuralNetworkRegressor,
        neuralNetworkClassifier = self.spec.neuralNetworkClassifier
    )
    nn = nn_dict[self.spec.WhichOneof(&#34;Type&#34;)]
    if nn is None: raise AttributeError(&#34;MLModel is not a neural network sub-class&#34;)
    return nn

### ------------------------------------------------ ###

# Field formatting functions
 # Item and line formatting functions

  _ph = &#39;~&#39;  # Placeholder char(s) for strings below ...
  @staticmethod
  def _tbd(self,l): return &#34;              - &#34;
  def _repf(self, rf): return str.join(&#39;x&#39;, [str(f) for f in rf]) if len(rf) != 0 else self._ph
  @staticmethod
  def _fmt_add(self,l): return f&#34;add     &#34;
  def _fmt_act(self,l): return f&#34;{l.activation.WhichOneof(&#39;NonlinearityType&#39;):8}&#34;
  def _fmt_pool(self, l): return f&#34;pool   &#34; + f&#34;          sz:{self._repf(l.pooling.kernelSize)}  str:{self._repf(l.pooling.stride)}&#34;
  def _fmt_concat(self, l): return f&#34;concat  &#34;
  def _fmt_reshape(self, l): return f&#34;reshape          target:{l.reshape.targetShape}&#34;

  def _fmt_bn(self, l):
    bn  = l.batchnorm
    bc  = f&#34;{bn.channels}&#34;
    return f&#34;bnorm  &#34; + f&#34;{bc:9} ep:{bn.epsilon:.3e}  wc:{len(bn.beta.floatValue) + len(bn.gamma.floatValue)}&#34;

  def _fmt_innerp(self, l):
    c   = l.innerProduct
    ic  = f&#34;{c.outputChannels}x{c.inputChannels}&#34;
    return f&#34;innerp &#34; + f&#34;{ic:9} wc:{len(c.weights.floatValue)}&#34;

  def _fmt_conv(self, l):
    c     = l.convolution
    kc    = f&#34;{c.outputChannels}x{c.kernelChannels}&#34;
    conv1 = f&#34;conv   &#34; + f&#34;{kc:9} sz:{self._repf(c.kernelSize)}  str:{self._repf(c.stride)}&#34;
    conv2 = f&#34;  dil:{self._repf(c.dilationFactor)}  wc:{len(c.weights.floatValue)}&#34;
    return conv1 + conv2

  # Maps layer types to formatting functions

  _fmt_funcs = dict(innerProduct=_fmt_innerp, reshape=_fmt_reshape,
                    convolution=_fmt_conv, batchnorm=_fmt_bn,
                    pooling=_fmt_pool, activation=_fmt_act,
                    add=_fmt_add, concat=_fmt_concat)

  def _fmt_shape(self, name: str) -&gt; str:
    &#34;&#34;&#34;
    Format the shape line
    &#34;&#34;&#34;
    try:
      s = self.shaper.shape(name)
    except IndexError as e:
      line = f&#34;      - {e} - &#34;
    else:
      line = f&#34;CHW: {s[&#39;C&#39;]} {s[&#39;H&#39;]} {s[&#39;W&#39;]}   SB:{s[&#39;S&#39;]}{s[&#39;B&#39;]}&#34;
    return line

  def _fmt_for_one_line(self, layer, li: int) -&gt; str:
    &#34;&#34;&#34;
    Format one nn layer to print on one line.

    This routine attempts (poorly, so far) to adjust field positions based
    on the length of the layer name.  Layer name length seems to vary
    from 3 chars (Models converted from ONNX) to 24 chars (Apple-generated CoreML models)

    &#34;&#34;&#34;
    # Field widths for one layer/line
    # layer = 3
    # layer_name (ln) = calculated (max 8)
    # shapes (assume 3x3-digit fields, on avg) = 9+2+2

    # Calculate and construct the parts for each line

    layer_typ   = layer.WhichOneof(&#39;layer&#39;)
    name_len    = self.name_len_centile
    _fmt_type   = self._fmt_funcs.get(layer_typ, self._tbd)

    w_inputs    = int(name_len * 2) + 4
    w_outputs   = name_len + 3

    layer_name  = format(f&#34;{layer.name}&#34;, f&#34;&lt;{name_len}s&#34;)
    inputs      = format(f&#34;[{str.join(&#39;, &#39;, layer.input)}]&#34;, f&#34;&lt;{w_inputs}s&#34;)
    outputs     = format(f&#34;[{str.join(&#39;, &#39;, layer.output)}]&#34;, f&#34;&lt;{w_outputs}s&#34;)
    shout       = self._fmt_shape(layer.name)

    # Assemble the line to print

    return f&#34;{li:3} {layer_name:5}  {inputs} {outputs} {shout:&gt;13}  {_fmt_type(self,layer)}&#34;

  def _fmt_for_two_lines(self,layer, li: int) -&gt; str:
    &#34;&#34;&#34;
    Format one nn layer to print on two lines.

    This routine attempts (poorly, so far) to adjust field positions based
    on the length of the layer name.  Layer name length seems to vary
    from 3 chars (Models converted from ONNX) up to 24 chars (Apple-generated CoreML models)

    &#34;&#34;&#34;

    # Calculate and construct the parts for each line

    layer_typ = layer.WhichOneof(&#39;layer&#39;)
    name_len  = self.name_len_centile
    _fmt_type = self._fmt_funcs.get(layer_typ, self._tbd)

    w_inputs  = name_len + 2  # int(name_len * 2) + 4
    w_outputs = name_len + 2

    sp         = f&#34;   &#34;
    layer_name = format(f&#34;{layer.name}&#34;, f&#34;&lt;{name_len}s&#34;)
    inputs     = format(f&#34;[{str.join(&#39;, &#39;, layer.input)}]&#34;, f&#34;&lt;{w_inputs}s&#34;)
    outputs    = format(f&#34;[{str.join(&#39;, &#39;, layer.output)}]&#34;, f&#34;&lt;{w_outputs}s&#34;)
    shout      = self._fmt_shape(layer.name)

    # Assemble the line(s) to print

    line1     = f&#34;{li:3} {layer_name:32} {inputs :&lt;24}  {_fmt_type(self,layer)}&#34;
    line2     = f&#34;{sp:3} {sp        :32} {outputs:&lt;24}  {shout}&#34;

    return line1 + &#34;\n&#34; + line2 + &#34;\n&#34;


  def show_nn(self,  start:Union[int,str]=0, count=4,  break_len=8 ) -&gt; None:
    &#34;&#34;&#34;
    Beginning at `nn` layer `start`, print a summary of `count` network layers

    Args:

      start (Union[int,str]): The starting layer. Can be an `int` (=&gt;Layer index) or a `str` (=&gt;Layer Name).
        Negative values work backward from the end, similar to lists.

      count (int): How many layers to summarize and print

      break_len (int): Formatting criteria. If most ( ~ 90% ) of the layer names are
        less than or equal to   &#34;break_len&#34;, one line is used, otherwise, two lines.

      Inconsistent or invalid values for start and count are repaired by reseting to appropriate defaults

    &#34;&#34;&#34;
    nn_count = self.layer_count

    # If necessary convert layer name to layer index
    if type(start) is str: start = self.layer_dict[start]

    # Fix any contradictory start and count values
    # If start is negative, simulate list behavior and work backwards from the end
    if count is None or count &lt;= 0 : count = 4
    if start &lt; 0                   : count = 3; start = nn_count + start
    if start + count &gt; nn_count    : start = nn_count - count

    sp = &#34;   &#34; # formatting spacer
    one_line_heading = f&#34;Lay Name{ sp:4}In{sp:8}Out{sp:6}Shapes{sp:7}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;
    two_line_heading = f&#34;Lay Name{sp:32}In/Out{sp:24}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;

    # If &gt;= 90% layer names are &#34;short&#34;, print layer on one line, otherwise use two
    if self.name_len_centile &lt;= break_len:
      format_layer = self._fmt_for_one_line
      heading      = one_line_heading
    else:
      format_layer = self._fmt_for_two_lines
      heading      = two_line_heading

    print(heading)

    # Format and print each layer, include shape values if available

    li = start

    for ly in self.layers[start:start+count]:
      print(format_layer(ly, li))
      li += 1


  &#34;&#34;&#34; 
  CoreML Model Surgery - connect and delete layers 
  &#34;&#34;&#34;

  def connect_layers(self, from_:str, to_:str, replace=True)-&gt;namedtuple:
    &#34;&#34;&#34;
    Connect the output of one CoreML model layer to the input of another.

    Layers are identified by name. An invalid layer name aborts any connection attempt.
    Note that when two layers are *connected*, only one layer is modified:
    the only field that changes is the **to** layer&#39;s *input* field. Note also
    that the  keyword arguments `from_` and `to_` are suffixed by underscores.

    Args:
      from_ (str): The name of the layer supplying the outputs

      to_ (str): The name of the layer receiving the `from` outputs.
                   This layer&#39;s `input` field is modified.

      replace (bool): *True* (default) Replaces (overwrites)
                  the &#39;to&#39; layer&#39;s input with the &#39;from&#39; layer&#39;s output.
                  *False* appends the &#39;from&#39; layer&#39;s output to the the &#39;to&#39; layer&#39;s input.

    Return:
      A named tuple describing the change (see examples that follow)

    Examples:

          cmb = CoremlBrowser( ... path to &#39;mlmodel&#39; file ...)

          cmb.connect_layers(from_=&#39;conv336&#39;, to_=&#39;bnorm409&#39;)

      returns:

          ( changed_layer = &#39;bnorm409&#39;,
            input_before  = [&#39;concat408_output&#39;, &#39;add400_output&#39;],
            input_after   = [&#39;conv336_output&#39;] )


          connect_layers(nn, from_=&#39;conv100&#39;, to_=&#39;concat408&#39;)

      returns:

          (changed_layer =  &#39;None&#39;, error = &#34;Layer [&#39;conv100&#39;] not found&#34;)

    &#34;&#34;&#34;
    from copy import deepcopy

    ldict        = self.layer_dict
    layers       = self.layers
    layer_change = namedtuple(&#39;layer_audit&#39;,&#39;changed_layer input_before input_after error&#39;)
    layer_names  = ldict.keys()
    missing      = [ name for name  in [from_, to_] if name not in layer_names ]

    if len(missing) &gt; 0: return layer_change(changed_layer = &#34;NONE&#34;,
                                             error         = f&#34;Layer(s) {[missing]} not found&#34;,
                                             input_before  = None,
                                             input_after   = None )
    from_layer   = layers[ldict[from_]]
    to_layer     = layers[ldict[to_]]
    input_before = deepcopy(to_layer.input)

    if replace :  # remove the current inputs
      for i in range(len(to_layer.input)):
        to_layer.input.pop()

    for i in range(len(from_layer.output)):
      to_layer.input.append(from_layer.output[i])

    return layer_change(changed_layer = to_layer.name,
                        input_before  = input_before,
                        input_after   = deepcopy(to_layer.input),
                        error = None )


  def delete_layers(self, names_to_delete:[str])-&gt;[dict]:
    &#34;&#34;&#34;
    Delete NN layers by **name**.  Invalid layer names are silently ignored.

    Args:
      names_to_delete ([str]): list of layer names

    Return:
      An array of dicts, one for each deletion

    Example:

          delete_layers(nn,[&#39;conv335&#39;,&#39;bn400&#39;,&#39;avt500&#39;]) # ( assume &#39;avt500&#39; does not exist)

        returns:
          [
            {&#39;deleted_layer&#39;: &#39;conv335&#39;,  &#39;input&#39;: [&#39;bn334&#39;], &#39;output&#39;: [&#39;conv335&#39;]},
            {&#39;deleted_layer&#39;: &#39;bn400&#39;, &#39;input&#39;: [&#39;conv399&#39;], &#39;output&#39;: [&#39;bn400&#39;]},
          ]

    &#34;&#34;&#34;
    from copy import deepcopy
    deleted = []

    for target_name in names_to_delete:
      # to be safe, we have to re-enumerate after every deletion
      for i, layer in enumerate(self.layers):
        if layer.name == target_name :
          deleted.append(
            dict( deleted_layer=target_name, input=deepcopy(layer.input), output=deepcopy(layer.output))
          )
          del self.layers[i]
          break

    # Update the layer count and layer dict kept by the Coreml browser instance
    self.layer_count = len(self.layers)
    self.layer_dict  = {layer.name:i for i,layer in enumerate(self.layers)}

    return deleted</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="coreml_help.CoremlBrowser.layer_dict"><code class="name">var <span class="ident">layer_dict</span></code></dt>
<dd>
<section class="desc"><p>Maps a layer name to its index</p></section>
</dd>
<dt id="coreml_help.CoremlBrowser.layers"><code class="name">var <span class="ident">layers</span></code></dt>
<dd>
<section class="desc"><p>Neural network layers</p></section>
</dd>
<dt id="coreml_help.CoremlBrowser.mlmodel_path"><code class="name">var <span class="ident">mlmodel_path</span></code></dt>
<dd>
<section class="desc"><p>Path to the mlmodel file</p></section>
</dd>
<dt id="coreml_help.CoremlBrowser.nn"><code class="name">var <span class="ident">nn</span></code></dt>
<dd>
<section class="desc"><p>Neural network layers object</p></section>
</dd>
<dt id="coreml_help.CoremlBrowser.shaper"><code class="name">var <span class="ident">shaper</span></code></dt>
<dd>
<section class="desc"><p>Shape inference object for this model</p></section>
</dd>
<dt id="coreml_help.CoremlBrowser.spec"><code class="name">var <span class="ident">spec</span></code></dt>
<dd>
<section class="desc"><p>(Protobuf) spec for the model</p></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="coreml_help.CoremlBrowser.connect_layers"><code class="name flex">
<span>def <span class="ident">connect_layers</span></span>(<span>self, from_, to_, replace=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Connect the output of one CoreML model layer to the input of another.</p>
<p>Layers are identified by name. An invalid layer name aborts any connection attempt.
Note that when two layers are <em>connected</em>, only one layer is modified:
the only field that changes is the <strong>to</strong> layer's <em>input</em> field. Note also
that the
keyword arguments <code>from_</code> and <code>to_</code> are suffixed by underscores.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>from_</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the layer supplying the outputs</dd>
<dt><strong><code>to_</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the layer receiving the <code>from</code> outputs.
This layer's <code>input</code> field is modified.</dd>
<dt><strong><code>replace</code></strong> :&ensp;<code>bool</code></dt>
<dd><em>True</em> (default) Replaces (overwrites)
the 'to' layer's input with the 'from' layer's output.
<em>False</em> appends the 'from' layer's output to the the 'to' layer's input.</dd>
</dl>
<h2 id="return">Return</h2>
<p>A named tuple describing the change (see examples that follow)</p>
<h2 id="examples">Examples</h2>
<pre><code>cmb = CoremlBrowser( ... path to 'mlmodel' file ...)

cmb.connect_layers(from_='conv336', to_='bnorm409')
</code></pre>
<p>returns:</p>
<pre><code>( changed_layer = 'bnorm409',
  input_before  = ['concat408_output', 'add400_output'],
  input_after   = ['conv336_output'] )


connect_layers(nn, from_='conv100', to_='concat408')
</code></pre>
<p>returns:</p>
<pre><code>(changed_layer =  'None', error = "Layer ['conv100'] not found")
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def connect_layers(self, from_:str, to_:str, replace=True)-&gt;namedtuple:
  &#34;&#34;&#34;
  Connect the output of one CoreML model layer to the input of another.

  Layers are identified by name. An invalid layer name aborts any connection attempt.
  Note that when two layers are *connected*, only one layer is modified:
  the only field that changes is the **to** layer&#39;s *input* field. Note also
  that the  keyword arguments `from_` and `to_` are suffixed by underscores.

  Args:
    from_ (str): The name of the layer supplying the outputs

    to_ (str): The name of the layer receiving the `from` outputs.
                 This layer&#39;s `input` field is modified.

    replace (bool): *True* (default) Replaces (overwrites)
                the &#39;to&#39; layer&#39;s input with the &#39;from&#39; layer&#39;s output.
                *False* appends the &#39;from&#39; layer&#39;s output to the the &#39;to&#39; layer&#39;s input.

  Return:
    A named tuple describing the change (see examples that follow)

  Examples:

        cmb = CoremlBrowser( ... path to &#39;mlmodel&#39; file ...)

        cmb.connect_layers(from_=&#39;conv336&#39;, to_=&#39;bnorm409&#39;)

    returns:

        ( changed_layer = &#39;bnorm409&#39;,
          input_before  = [&#39;concat408_output&#39;, &#39;add400_output&#39;],
          input_after   = [&#39;conv336_output&#39;] )


        connect_layers(nn, from_=&#39;conv100&#39;, to_=&#39;concat408&#39;)

    returns:

        (changed_layer =  &#39;None&#39;, error = &#34;Layer [&#39;conv100&#39;] not found&#34;)

  &#34;&#34;&#34;
  from copy import deepcopy

  ldict        = self.layer_dict
  layers       = self.layers
  layer_change = namedtuple(&#39;layer_audit&#39;,&#39;changed_layer input_before input_after error&#39;)
  layer_names  = ldict.keys()
  missing      = [ name for name  in [from_, to_] if name not in layer_names ]

  if len(missing) &gt; 0: return layer_change(changed_layer = &#34;NONE&#34;,
                                           error         = f&#34;Layer(s) {[missing]} not found&#34;,
                                           input_before  = None,
                                           input_after   = None )
  from_layer   = layers[ldict[from_]]
  to_layer     = layers[ldict[to_]]
  input_before = deepcopy(to_layer.input)

  if replace :  # remove the current inputs
    for i in range(len(to_layer.input)):
      to_layer.input.pop()

  for i in range(len(from_layer.output)):
    to_layer.input.append(from_layer.output[i])

  return layer_change(changed_layer = to_layer.name,
                      input_before  = input_before,
                      input_after   = deepcopy(to_layer.input),
                      error = None )</code></pre>
</details>
</dd>
<dt id="coreml_help.CoremlBrowser.delete_layers"><code class="name flex">
<span>def <span class="ident">delete_layers</span></span>(<span>self, names_to_delete)</span>
</code></dt>
<dd>
<section class="desc"><p>Delete NN layers by <strong>name</strong>.
Invalid layer names are silently ignored.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>names_to_delete</code></strong> :&ensp;[<code>str</code>]</dt>
<dd>list of layer names</dd>
</dl>
<h2 id="return">Return</h2>
<p>An array of dicts, one for each deletion</p>
<h2 id="example">Example</h2>
<p>delete_layers(nn,['conv335','bn400','avt500']) # ( assume 'avt500' does not exist)</p>
<p>returns:
[
{'deleted_layer': 'conv335',
'input': ['bn334'], 'output': ['conv335']},
{'deleted_layer': 'bn400', 'input': ['conv399'], 'output': ['bn400']},
]</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def delete_layers(self, names_to_delete:[str])-&gt;[dict]:
  &#34;&#34;&#34;
  Delete NN layers by **name**.  Invalid layer names are silently ignored.

  Args:
    names_to_delete ([str]): list of layer names

  Return:
    An array of dicts, one for each deletion

  Example:

        delete_layers(nn,[&#39;conv335&#39;,&#39;bn400&#39;,&#39;avt500&#39;]) # ( assume &#39;avt500&#39; does not exist)

      returns:
        [
          {&#39;deleted_layer&#39;: &#39;conv335&#39;,  &#39;input&#39;: [&#39;bn334&#39;], &#39;output&#39;: [&#39;conv335&#39;]},
          {&#39;deleted_layer&#39;: &#39;bn400&#39;, &#39;input&#39;: [&#39;conv399&#39;], &#39;output&#39;: [&#39;bn400&#39;]},
        ]

  &#34;&#34;&#34;
  from copy import deepcopy
  deleted = []

  for target_name in names_to_delete:
    # to be safe, we have to re-enumerate after every deletion
    for i, layer in enumerate(self.layers):
      if layer.name == target_name :
        deleted.append(
          dict( deleted_layer=target_name, input=deepcopy(layer.input), output=deepcopy(layer.output))
        )
        del self.layers[i]
        break

  # Update the layer count and layer dict kept by the Coreml browser instance
  self.layer_count = len(self.layers)
  self.layer_dict  = {layer.name:i for i,layer in enumerate(self.layers)}

  return deleted</code></pre>
</details>
</dd>
<dt id="coreml_help.CoremlBrowser.get_nn"><code class="name flex">
<span>def <span class="ident">get_nn</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the layers object for a CoreML neural network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spec</code></strong> :&ensp;<code>Model</code></dt>
<dd>The <code>protobuf</code> spec. for this CoreML model.
Returned by <code>coremltools.util.load_spec("file.mlmodel")</code></dd>
</dl>
<h2 id="return">Return</h2>
<p>The neural network layers of the model or an Attribute Error.
The precise return type is determined by the value of <code>spec.WhichOneof("Type")</code>,
which should be one of:</p>
<ul>
<li>Model.neuralNetwork</li>
<li>Model.neuralNetworkClassifier</li>
<li>Model.neuralNetworkRegressor</li>
</ul>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>AttributeError</code></strong></dt>
<dd>if spec is not one of the 3 neuralNetwork sub-classes</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_nn(self) -&gt; Model_pb2.Model.neuralNetwork:
  &#34;&#34;&#34;
  Get the layers object for a CoreML neural network.

  Args:
    spec (Model): The `protobuf` spec. for this CoreML model.
                  Returned by `coremltools.util.load_spec(&#34;file.mlmodel&#34;)`

  Return:
    The neural network layers of the model or an Attribute Error.
    The precise return type is determined by the value of `spec.WhichOneof(&#34;Type&#34;)`,
    which should be one of:

      - Model.neuralNetwork
      - Model.neuralNetworkClassifier
      - Model.neuralNetworkRegressor

  Raises:
    AttributeError: if spec is not one of the 3 neuralNetwork sub-classes

  &#34;&#34;&#34;

  nn_dict = dict(
      neuralNetwork = self.spec.neuralNetwork,
      neuralNetworkRegressor = self.spec.neuralNetworkRegressor,
      neuralNetworkClassifier = self.spec.neuralNetworkClassifier
  )
  nn = nn_dict[self.spec.WhichOneof(&#34;Type&#34;)]
  if nn is None: raise AttributeError(&#34;MLModel is not a neural network sub-class&#34;)
  return nn</code></pre>
</details>
</dd>
<dt id="coreml_help.CoremlBrowser.show_nn"><code class="name flex">
<span>def <span class="ident">show_nn</span></span>(<span>self, start=0, count=4, break_len=8)</span>
</code></dt>
<dd>
<section class="desc"><p>Beginning at <code>nn</code> layer <code>start</code>, print a summary of <code>count</code> network layers</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>Union</code>[<code>int</code>,<code>str</code>]</dt>
<dd>The starting layer. Can be an <code>int</code> (=&gt;Layer index) or a <code>str</code> (=&gt;Layer Name).
Negative values work backward from the end, similar to lists.</dd>
<dt><strong><code>count</code></strong> :&ensp;<code>int</code></dt>
<dd>How many layers to summarize and print</dd>
<dt><strong><code>break_len</code></strong> :&ensp;<code>int</code></dt>
<dd>Formatting criteria. If most ( ~ 90% ) of the layer names are
less than or equal to
"break_len", one line is used, otherwise, two lines.</dd>
</dl>
<p>Inconsistent or invalid values for start and count are repaired by reseting to appropriate defaults</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def show_nn(self,  start:Union[int,str]=0, count=4,  break_len=8 ) -&gt; None:
  &#34;&#34;&#34;
  Beginning at `nn` layer `start`, print a summary of `count` network layers

  Args:

    start (Union[int,str]): The starting layer. Can be an `int` (=&gt;Layer index) or a `str` (=&gt;Layer Name).
      Negative values work backward from the end, similar to lists.

    count (int): How many layers to summarize and print

    break_len (int): Formatting criteria. If most ( ~ 90% ) of the layer names are
      less than or equal to   &#34;break_len&#34;, one line is used, otherwise, two lines.

    Inconsistent or invalid values for start and count are repaired by reseting to appropriate defaults

  &#34;&#34;&#34;
  nn_count = self.layer_count

  # If necessary convert layer name to layer index
  if type(start) is str: start = self.layer_dict[start]

  # Fix any contradictory start and count values
  # If start is negative, simulate list behavior and work backwards from the end
  if count is None or count &lt;= 0 : count = 4
  if start &lt; 0                   : count = 3; start = nn_count + start
  if start + count &gt; nn_count    : start = nn_count - count

  sp = &#34;   &#34; # formatting spacer
  one_line_heading = f&#34;Lay Name{ sp:4}In{sp:8}Out{sp:6}Shapes{sp:7}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;
  two_line_heading = f&#34;Lay Name{sp:32}In/Out{sp:24}Type,Chan(s){sp:7}Size,Stride,Dilation,#Wts&#34;

  # If &gt;= 90% layer names are &#34;short&#34;, print layer on one line, otherwise use two
  if self.name_len_centile &lt;= break_len:
    format_layer = self._fmt_for_one_line
    heading      = one_line_heading
  else:
    format_layer = self._fmt_for_two_lines
    heading      = two_line_heading

  print(heading)

  # Format and print each layer, include shape values if available

  li = start

  for ly in self.layers[start:start+count]:
    print(format_layer(ly, li))
    li += 1</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="coreml_help.ImageRepo"><code class="flex name class">
<span>class <span class="ident">ImageRepo</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>ImageRepo(mean, std, labels_url)</p></section>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="coreml_help.ImageRepo.labels_url"><code class="name">var <span class="ident">labels_url</span></code></dt>
<dd>
<section class="desc"><p>Alias for field number 2</p></section>
</dd>
<dt id="coreml_help.ImageRepo.mean"><code class="name">var <span class="ident">mean</span></code></dt>
<dd>
<section class="desc"><p>Alias for field number 0</p></section>
</dd>
<dt id="coreml_help.ImageRepo.std"><code class="name">var <span class="ident">std</span></code></dt>
<dd>
<section class="desc"><p>Alias for field number 1</p></section>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="coreml_help.get_rand_images" href="#coreml_help.get_rand_images">get_rand_images</a></code></li>
<li><code><a title="coreml_help.get_shapes" href="#coreml_help.get_shapes">get_shapes</a></code></li>
<li><code><a title="coreml_help.main" href="#coreml_help.main">main</a></code></li>
<li><code><a title="coreml_help.norm_for_imagenet" href="#coreml_help.norm_for_imagenet">norm_for_imagenet</a></code></li>
<li><code><a title="coreml_help.pred_for_coreml" href="#coreml_help.pred_for_coreml">pred_for_coreml</a></code></li>
<li><code><a title="coreml_help.pred_for_o2c" href="#coreml_help.pred_for_o2c">pred_for_o2c</a></code></li>
<li><code><a title="coreml_help.pred_for_onnx" href="#coreml_help.pred_for_onnx">pred_for_onnx</a></code></li>
<li><code><a title="coreml_help.show_head" href="#coreml_help.show_head">show_head</a></code></li>
<li><code><a title="coreml_help.show_nn" href="#coreml_help.show_nn">show_nn</a></code></li>
<li><code><a title="coreml_help.show_tail" href="#coreml_help.show_tail">show_tail</a></code></li>
<li><code><a title="coreml_help.softmax" href="#coreml_help.softmax">softmax</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="coreml_help.CoremlBrowser" href="#coreml_help.CoremlBrowser">CoremlBrowser</a></code></h4>
<ul class="">
<li><code><a title="coreml_help.CoremlBrowser.connect_layers" href="#coreml_help.CoremlBrowser.connect_layers">connect_layers</a></code></li>
<li><code><a title="coreml_help.CoremlBrowser.delete_layers" href="#coreml_help.CoremlBrowser.delete_layers">delete_layers</a></code></li>
<li><code><a title="coreml_help.CoremlBrowser.get_nn" href="#coreml_help.CoremlBrowser.get_nn">get_nn</a></code></li>
<li><code><a title="coreml_help.CoremlBrowser.show_nn" href="#coreml_help.CoremlBrowser.show_nn">show_nn</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="coreml_help.ImageRepo" href="#coreml_help.ImageRepo">ImageRepo</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>